# -*- coding: utf-8 -*-
"""LVDSUSR172_Niveditha_3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rrmt7W5iDXSAM__zupcOgNdWc83iNoOS
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import silhouette_score

df = pd.read_csv("/content/customer_segmentation.csv").drop(['ID', 'Dt_Customer', 'Z_CostContact', 'Z_Revenue'], axis = 1)

df.info()

df.isnull().sum()

df['Income'] = df['Income'].fillna(df['Income'].median())

df

numerical_columns = df.columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(20, 6))
    sns.histplot(df[column])
    plt.title(f'Bar Plot of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

plt.figure(figsize = (15,15))
sns.heatmap(df.corr(numeric_only = True), annot = True)

plt.figure(figsize = (20,5))
sns.boxplot(df)

#IQR
q1 = np.percentile(df['Income'],0.25)
q3 = np.percentile(df['Income'],0.75)
print(q1,q3)
iqr = q3-q1
print(iqr)
ul = q3 + 1.5 * iqr
ll = q1 - 1.5 * iqr
print(ul,ll)
df = df[(df['Income'] >= ll) & (df['Income'] <= ul)]

df['Education'].value_counts()

df.columns
dff = df[['Income', 'Kidhome',
       'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',
       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',
       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',
       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',
       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',
       'Complain', 'Response']]

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
cols = ['Education', 'Marital_Status']
for column in cols:
  df[column] = le.fit_transform(df[column])

df

minmax = MinMaxScaler()
encoded_df = minmax.fit_transform(df)

#WCSS K-MEANS

from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(encoded_df)
    wcss.append(kmeans.inertia_)

# Plot the elbow method graph
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='-')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
plt.xticks(np.arange(1, 11, 1))
plt.grid(True)
plt.show()

centers

encoded_df

kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(encoded_df)
labels = kmeans.labels_
df['clusters'] = labels
centers = kmeans.cluster_centers_

# K-MEANS EVALUVATION METRICS

from sklearn.metrics import silhouette_score
print(silhouette_score(encoded_df,kmeans.labels_))

plt.figure(figsize=(8, 6))
plt.scatter(encoded_df[:0], encoded_df[:1], c=df['clusters'], cmap='viridis', s=50, alpha=0.5)

# Assign names to the clusters
cluster_names = ['Cluster 1', 'Cluster 2', 'Cluster 3']

# Create legend with cluster names
for i, cluster_name in enumerate(cluster_names):
    plt.scatter([], [], label=cluster_name, c=plt.cm.viridis(i / (len(cluster_names) - 1)), alpha=0.5)

plt.title('K-means Clustering')
plt.xlabel('X1')
plt.ylabel('X2')
plt.legend()
plt.show()





